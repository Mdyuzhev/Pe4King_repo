# Роадмап LLM-интеграции

Документ описывает планируемое развитие интеграции Pe4King с языковыми моделями. Текущая версия Pe4King работает полностью автономно, генерируя скелетные тесты детерминистически. LLM-интеграция — это опциональное расширение для повышения качества тестов.

---

## Фаза 1: Базовый адаптер

Реализация универсального адаптера для работы с LLM-провайдерами.

### Компоненты

Интерфейс LlmProvider с методами complete(), isAvailable(), estimateTokens(). PromptBuilder для формирования промптов из шаблонов. ResponseParser для извлечения кода из ответов модели. Хранение API-ключей в защищённом хранилище операционной системы.

### Результат

Возможность синхронного улучшения отдельного теста через UI. Пользователь выбирает тест, нажимает "Улучшить с AI", получает результат через несколько секунд.

### Ограничения фазы

Работа только с одним тестом за раз. Улучшение на основе схемы из OpenAPI, без реальных данных. Синхронный режим — пользователь ждёт ответа.

---

## Фаза 2: Сбор реальных ответов

Расширение Test Runner для сбора полных ответов от реального API.

### Концепция

Скелетные тесты генерируются по OpenAPI-схеме. Схема описывает структуру, но не содержит реальных данных. Первый прогон тестов на реальном API даёт конкретные примеры ответов: какие значения возвращаются в полях, какая реальная вложенность, какие enum-значения используются на практике.

### Компоненты

ResponseCollector — компонент Test Runner, который сохраняет полный ответ для каждого выполненного запроса. TestRunReport — структура данных, связывающая код теста с полученным ответом. Локальное хранилище для сохранения результатов прогона.

### Формат собираемых данных

```
TestRunReport {
    test_file: "UserApiTest.java"
    test_method: "testGetUserById"
    endpoint: "GET /users/{id}"
    request: {
        url: "https://api.example.com/users/123"
        headers: {...}
        body: null
    }
    response: {
        status: 200
        headers: {...}
        body: {полный JSON ответа}
        time_ms: 145
    }
    test_result: PASSED | FAILED
    failure_reason: null | "Expected 200, got 404"
    timestamp: "2025-01-29T10:30:00Z"
}
```

### Результат

После прогона тестов пользователь имеет коллекцию реальных ответов, привязанных к конкретным тестам. Эти данные можно использовать для более качественного улучшения.

---

## Фаза 3: Асинхронный batch-режим

Обработка большого количества тестов через асинхронный API.

### Проблема синхронного режима

Синхронное улучшение работает для одного-двух тестов. Но типичный проект содержит сотни тестов. Улучшать их по одному — часы ручной работы. Отправлять сотни синхронных запросов — дорого и медленно.

### Решение

Batch API провайдеров (Anthropic, OpenAI) позволяет отправить пакет запросов и получить результат через некоторое время. Стоимость batch-запросов в 2-4 раза ниже синхронных. Время обработки — от минут до часов в зависимости от размера пакета и загрузки провайдера.

### Workflow

Этап 1: Генерация. Пользователь генерирует скелетные тесты через Pe4King как обычно. Получает базовые тесты с assertions уровня L2-L3 по EVA.

Этап 2: Первый прогон. Пользователь запускает тесты на реальном API (staging или dev environment). Test Runner выполняет запросы и собирает реальные ответы в TestRunReport.

Этап 3: Формирование пакета. Плагин формирует EnhancementRequest — пакет, содержащий для каждого теста: код скелета, схему endpoint'а из OpenAPI, реальный ответ из прогона.

Этап 4: Отправка. Пакет отправляется в LLM Batch API. Пользователь получает task_id и уведомление "Обработка займёт примерно 30-60 минут". Пользователь может закрыть IDE и продолжить другую работу.

Этап 5: Ожидание. Плагин периодически проверяет статус задачи (polling) или получает уведомление через webhook. Состояние задачи сохраняется локально, чтобы пережить перезапуск IDE.

Этап 6: Получение результата. Когда обработка завершена, пользователь получает нотификацию. Открывает панель результатов, видит diff для каждого теста: было → стало.

Этап 7: Применение. Пользователь просматривает изменения, может применить все сразу или выборочно. После применения получает тесты с assertions на реальных данных — уровень L4-L5 по EVA.

### Что даёт реальный ответ

Сравнение улучшения по схеме и по реальным данным.

По схеме (OpenAPI говорит "status — string"):
```java
.body("status", notNullValue())
```

По реальным данным (ответ содержит "status": "active"):
```java
.body("status", oneOf("active", "inactive", "pending", "archived"))
```

LLM видит реальное значение и может вывести множество допустимых значений, проверить формат UUID по реальному примеру, понять структуру вложенных объектов, определить паттерны в данных.

### Компоненты

EnhancementRequestBuilder — собирает пакет из скелетов и реальных ответов. BatchApiClient — отправляет пакет в Batch API провайдера. TaskStateManager — хранит состояние задач локально, переживает перезапуск IDE. NotificationService — уведомляет пользователя о готовности. EnhancementResultViewer — UI для просмотра и применения улучшений.

---

## Фаза 4: Умное применение

Автоматическая валидация и применение улучшений.

### Проблема

LLM может сгенерировать некомпилируемый код, особенно если используется маленькая или локальная модель. Слепое применение таких улучшений сломает проект.

### Решение

Перед применением каждое улучшение проходит валидацию: синтаксический анализ (парсится ли код), проверка импортов (все ли классы доступны), опциональная компиляция (для Java).

Результаты валидации отображаются в UI: зелёная галочка — можно применять безопасно, жёлтый треугольник — есть предупреждения, красный крест — код не компилируется.

### Автоматический retry

Если улучшение не прошло валидацию, система может автоматически запросить исправление у LLM, передав сообщение об ошибке. Количество retry ограничено (обычно 2-3 попытки).

---

## Фаза 5: Непрерывное улучшение

Интеграция в CI/CD pipeline.

### Концепция

После каждого прогона тестов в CI автоматически собираются реальные ответы. Если обнаружены новые паттерны данных (новые enum-значения, изменившаяся структура), система предлагает обновить тесты.

### Workflow в CI

CI запускает тесты, ResponseCollector собирает ответы. Система сравнивает текущие assertions с реальными данными. Если есть расхождения (тест проверяет "active", а API вернул "activated"), создаётся задача на улучшение. Результат улучшения оформляется как Pull Request.

### Компоненты

CiIntegration — модуль для работы в headless-режиме. DriftDetector — обнаруживает расхождения между тестами и реальностью. PrCreator — создаёт PR с предложенными изменениями.

---

## Технические решения

### Хранение состояния задач

Асинхронные задачи должны переживать перезапуск IDE. Варианты хранения: SQLite база в директории проекта, JSON-файл в .pe4king/, облачный сервис если делаем SaaS-версию.

Структура состояния:
```
Task {
    id: "task-uuid"
    status: PENDING | PROCESSING | COMPLETED | FAILED
    created_at: timestamp
    completed_at: timestamp | null
    request_hash: "sha256..."  // для дедупликации
    result_path: "path/to/result.json" | null
    error: "error message" | null
}
```

### Маскирование чувствительных данных

Реальные ответы API могут содержать чувствительные данные: персональные данные (email, телефоны, адреса), токены и ключи в заголовках, внутренние идентификаторы.

Перед отправкой в LLM применяется маскирование: email → user@example.com, UUID → 00000000-0000-0000-0000-000000000001, токены → [MASKED].

Маскирование настраивается пользователем: можно отключить полностью (для локальных моделей), выбрать уровень (минимальный, стандартный, параноидальный), добавить кастомные правила.

### Разбиение больших пакетов

Batch API имеет ограничения на размер запроса. Если проект содержит 500 тестов, пакет нужно разбить на chunks. Каждый chunk отправляется как отдельный batch-запрос. Результаты собираются воедино после завершения всех chunks.

### Обработка изменений API

Между первым прогоном и применением улучшений API мог измениться. При применении система проверяет: не изменилась ли OpenAPI-спецификация, не устарели ли собранные ответы (timestamp). Если обнаружены изменения — предупреждение пользователю.

---

## Приоритизация

| Фаза | Ценность | Сложность | Приоритет |
|------|----------|-----------|-----------|
| 1. Базовый адаптер | Средняя | Низкая | P1 |
| 2. Сбор ответов | Высокая | Низкая | P1 |
| 3. Async batch | Очень высокая | Средняя | P1 |
| 4. Умное применение | Средняя | Средняя | P2 |
| 5. CI/CD интеграция | Высокая | Высокая | P3 |

Фазы 1-3 дают основную ценность и должны быть реализованы вместе. Фазы 4-5 — улучшения для enterprise-использования.

---

## Метрики успеха

### Качество улучшений

EVA score до и после улучшения. Целевой прирост: с L2-L3 до L4-L5 (с 25-50 до 70-85 баллов).

### Принятие пользователем

Процент принятых улучшений (acceptance rate). Целевой показатель: более 80% улучшений применяются без правок.

### Экономия времени

Время на ручное написание аналогичных assertions vs время на review и применение улучшений. Целевая экономия: 5-10x.

---

## Ограничения и риски

### Качество зависит от модели

Маленькие локальные модели могут генерировать некачественные улучшения. Рекомендация: использовать модели от 7B параметров для этой задачи.

### Стоимость облачных провайдеров

Batch API дешевле синхронного, но при большом объёме счета могут быть значительными. Рекомендация: показывать estimated cost перед отправкой.

### Latency batch-режима

Время обработки непредсказуемо: от минут до часов. Рекомендация: устанавливать ожидания пользователя, показывать прогресс.

### Изменчивость API

Реальные данные устаревают. Рекомендация: timestamp на отчётах, предупреждения при применении устаревших улучшений.

---

## Автор

Mikhail Dyuzhev

---

*Документ: LLM_INTEGRATION_ROADMAP.md*
*Версия: 1.0*
*Проект: Pe4King*
